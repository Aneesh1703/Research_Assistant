APP_NAME=Research Assistant
DEBUG=True
EMBEDDING_MODEL=all-MiniLM-L6-v2
VECTOR_DB_PATH=data/embeddings/faiss_index
GEMINI_API_KEY=your_actual_gemini_api_key_here



# App Configuration
APP_NAME=Research Assistant
APP_VERSION=0.1.0
DEBUG=True

# API Configuration
API_HOST=127.0.0.1
API_PORT=8000
API_PREFIX=/api/v1

# CORS Settings (you can leave these as defaults)
# The app will use the defaults from config.py

# File Upload Settings (optional - defaults will be used)
# MAX_UPLOAD_SIZE=10485760
# ALLOWED_EXTENSIONS=.pdf,.txt,.md

# Data Paths (optional - defaults will be used)
# DATA_DIR=data
# RAW_DATA_DIR=data/raw
# PROCESSED_DATA_DIR=data/processed
# CACHE_DIR=data/cache
# EMBEDDINGS_DIR=data/embeddings

# RAG Configuration (optional - for future use)
# EMBEDDING_MODEL=all-MiniLM-L6-v2
# VECTOR_DB_PATH=data/embeddings/faiss_index
# CHUNK_SIZE=500
# CHUNK_OVERLAP=50

# LLM Configuration (OPTIONAL - leave empty for API-only testing)
GEMINI_API_KEY=

# If you have a Gemini API key, add it here:
# GEMINI_API_KEY=your_actual_api_key_here

# LLM Settings (optional)
# LLM_TEMPERATURE=0.7
# LLM_MAX_TOKENS=1000
